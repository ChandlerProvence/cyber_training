{"cells":[{"cell_type":"markdown","id":"f82b1e60","metadata":{"id":"f82b1e60"},"source":["#  <span style=\"color:#0b186c;\">Introduction to Intrusion Detection Systems (IDS)</span>\n","\n","---\n","\n","An Intrusion Detection System (IDS) is a system that **monitors** network traffic for suspicious activity and issues alerts when such activity is discovered. These systems can be applications that sit at specific network locations and can be tailored to search for known threats as well as abnormal behavior.\n","\n","<br></br>\n","## <span style=\"color:#0b186c;\">Table of Contents:</span>\n","* [Project Description](#first-bullet)\n","* [Dataset Information](#second-bullet)\n","* [Data Preprocessing](#third-bullet)\n","* [Initial Model Development](#fourth-bullet)\n","* [Dimensionality Reduction](#fifth-bullet)\n","* [Conclusion](#sixth-bullet)"]},{"cell_type":"markdown","id":"ec077397","metadata":{"id":"ec077397"},"source":["#  <span style=\"color:#0b186c;\">Project Description</span><a class=\"anchor\" id=\"first-bullet\"></a>\n","\n","---\n","\n","Intrusion Detection Systems can use different methods to detect suspicious activities, which can be broadly divided into:\n","\n","- **Signature-based intrusion detection** – These systems compare the incoming traffic with a pre-existing database of known attack patterns known as signatures.\n","\n","- **Anomaly-based intrusion detection** – It uses statistics to form a baseline usage of the networks at different time intervals. They were introduced to detect unknown attacks. This system uses machine learning to create a model simulating regular activity and then compares new behaviour with the existing model.\n","\n","## <span style=\"color:#0b186c;\">Required Imports:</span>\n","\n","<div class=\"alert alert-warning\">\n","\n","<b>Note:</b> If you have not previously installed these `packages`, you can use the cell below to perform the required `pip` installs.\n","\n","</div>"]},{"cell_type":"code","execution_count":null,"id":"e44b9c6d","metadata":{"id":"e44b9c6d"},"outputs":[],"source":["# In case you still need to perform some pip installs:\n","! pip install --user pandas -q\n","! pip install --user numpy -q\n","! pip install --user scikit-learn -q"]},{"cell_type":"code","execution_count":null,"id":"17bb9bcc","metadata":{"id":"17bb9bcc"},"outputs":[],"source":["# Dataframe and array libraries\n","import pandas as pd\n","import numpy as np\n","\n","# Libraries for visualizing data\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Required for performing standardization robust to outliers\n","from sklearn.preprocessing import RobustScaler\n","\n","# Required for performing encoding on categorical input variables\n","from sklearn.preprocessing import OrdinalEncoder\n","\n","# Required for performing encoding categorical input variables into new columns\n","from sklearn.preprocessing import OneHotEncoder\n","\n","# Required for instantiating and running a Decision Tree model\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn import tree\n","\n","# Classification metrics and confusion matrix\n","from sklearn.metrics import confusion_matrix, accuracy_score, plot_confusion_matrix, ConfusionMatrixDisplay\n","\n","# Required for performing dimensionality reduction\n","from sklearn.decomposition import PCA\n","\n","# Filters out warning messages\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","id":"9f181a16","metadata":{"id":"9f181a16"},"source":["#  <span style=\"color:#0b186c;\">Dataset Information</span><a class=\"anchor\" id=\"second-bullet\"></a>\n","\n","---\n","\n","Widely considered the *Hello World* of IDS Machine Learning, the KDD '99 dataset is used to create Supervised Machine Learning models capable of distinguishing normal network behavior from intrusions of varied attack types. The original dataset originated from the Third International Knowledge Discovery and Data Mining Tools Competition, which was held in conjunction with KDD-99 the Fifth International Conference on Knowledge Discovery and Data Mining. The competition task was to build a network intrusion detector, a predictive model capable of distinguishing between bad connections, called intrusions or attacks, and good normal connections. This database contains a standard set of data to be audited, which includes a wide variety of intrusions simulated in a military network environment.\n","\n","NSL-KDD is a dataset suggested to solve some of the inherent problems of the KDD'99 data set, which included a large amount of redundant and duplicate records. The improvements made on the dataset reduce the potential for bias towards better detection rates on the more frequent records. The dataset is maintained by the Canandian Institute of Cybersecurity:\n","\n","https://www.unb.ca/cic/datasets/nsl.html"]},{"cell_type":"code","source":["from google.colab import files\n","uploaded = files.upload()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":108},"id":"Ef0HcoJyDQd6","executionInfo":{"status":"ok","timestamp":1664804131856,"user_tz":240,"elapsed":130512,"user":{"displayName":"Chandler Provence","userId":"03181162782867069084"}},"outputId":"8faa81c6-6909-4a68-d014-747f04321040"},"id":"Ef0HcoJyDQd6","execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-077c6f3f-de89-436f-ab6c-0f1949ccfe46\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-077c6f3f-de89-436f-ab6c-0f1949ccfe46\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving KDDTest.csv to KDDTest.csv\n","Saving KDDTrain.csv to KDDTrain.csv\n"]}]},{"cell_type":"code","execution_count":null,"id":"cc6363e3","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":505},"id":"cc6363e3","executionInfo":{"status":"ok","timestamp":1664804194218,"user_tz":240,"elapsed":2371,"user":{"displayName":"Chandler Provence","userId":"03181162782867069084"}},"outputId":"f64507dd-62f2-4990-bbbf-3c76f914d8b3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training Set:\n"]},{"output_type":"execute_result","data":{"text/plain":["        duration protocol_type   service flag  src_bytes  dst_bytes  land  \\\n","0              0           tcp  ftp_data   SF        491          0     0   \n","1              0           udp     other   SF        146          0     0   \n","2              0           tcp   private   S0          0          0     0   \n","3              0           tcp      http   SF        232       8153     0   \n","4              0           tcp      http   SF        199        420     0   \n","...          ...           ...       ...  ...        ...        ...   ...   \n","125968         0           tcp   private   S0          0          0     0   \n","125969         8           udp   private   SF        105        145     0   \n","125970         0           tcp      smtp   SF       2231        384     0   \n","125971         0           tcp    klogin   S0          0          0     0   \n","125972         0           tcp  ftp_data   SF        151          0     0   \n","\n","        wrong_fragment  urgent  hot  ...  dst_host_same_srv_rate  \\\n","0                    0       0    0  ...                    0.17   \n","1                    0       0    0  ...                    0.00   \n","2                    0       0    0  ...                    0.10   \n","3                    0       0    0  ...                    1.00   \n","4                    0       0    0  ...                    1.00   \n","...                ...     ...  ...  ...                     ...   \n","125968               0       0    0  ...                    0.10   \n","125969               0       0    0  ...                    0.96   \n","125970               0       0    0  ...                    0.12   \n","125971               0       0    0  ...                    0.03   \n","125972               0       0    0  ...                    0.30   \n","\n","        dst_host_diff_srv_rate  dst_host_same_src_port_rate  \\\n","0                         0.03                         0.17   \n","1                         0.60                         0.88   \n","2                         0.05                         0.00   \n","3                         0.00                         0.03   \n","4                         0.00                         0.00   \n","...                        ...                          ...   \n","125968                    0.06                         0.00   \n","125969                    0.01                         0.01   \n","125970                    0.06                         0.00   \n","125971                    0.05                         0.00   \n","125972                    0.03                         0.30   \n","\n","        dst_host_srv_diff_host_rate  dst_host_serror_rate  \\\n","0                              0.00                  0.00   \n","1                              0.00                  0.00   \n","2                              0.00                  1.00   \n","3                              0.04                  0.03   \n","4                              0.00                  0.00   \n","...                             ...                   ...   \n","125968                         0.00                  1.00   \n","125969                         0.00                  0.00   \n","125970                         0.00                  0.72   \n","125971                         0.00                  1.00   \n","125972                         0.00                  0.00   \n","\n","        dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n","0                           0.00                  0.05   \n","1                           0.00                  0.00   \n","2                           1.00                  0.00   \n","3                           0.01                  0.00   \n","4                           0.00                  0.00   \n","...                          ...                   ...   \n","125968                      1.00                  0.00   \n","125969                      0.00                  0.00   \n","125970                      0.00                  0.01   \n","125971                      1.00                  0.00   \n","125972                      0.00                  0.00   \n","\n","        dst_host_srv_rerror_rate   target  difficulty  \n","0                           0.00   normal          20  \n","1                           0.00   normal          15  \n","2                           0.00  neptune          19  \n","3                           0.01   normal          21  \n","4                           0.00   normal          21  \n","...                          ...      ...         ...  \n","125968                      0.00  neptune          20  \n","125969                      0.00   normal          21  \n","125970                      0.00   normal          18  \n","125971                      0.00  neptune          20  \n","125972                      0.00   normal          21  \n","\n","[125973 rows x 43 columns]"],"text/html":["\n","  <div id=\"df-f0cf3a28-edf6-4e49-91ac-11878c44c693\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>duration</th>\n","      <th>protocol_type</th>\n","      <th>service</th>\n","      <th>flag</th>\n","      <th>src_bytes</th>\n","      <th>dst_bytes</th>\n","      <th>land</th>\n","      <th>wrong_fragment</th>\n","      <th>urgent</th>\n","      <th>hot</th>\n","      <th>...</th>\n","      <th>dst_host_same_srv_rate</th>\n","      <th>dst_host_diff_srv_rate</th>\n","      <th>dst_host_same_src_port_rate</th>\n","      <th>dst_host_srv_diff_host_rate</th>\n","      <th>dst_host_serror_rate</th>\n","      <th>dst_host_srv_serror_rate</th>\n","      <th>dst_host_rerror_rate</th>\n","      <th>dst_host_srv_rerror_rate</th>\n","      <th>target</th>\n","      <th>difficulty</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>tcp</td>\n","      <td>ftp_data</td>\n","      <td>SF</td>\n","      <td>491</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0.17</td>\n","      <td>0.03</td>\n","      <td>0.17</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.05</td>\n","      <td>0.00</td>\n","      <td>normal</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>udp</td>\n","      <td>other</td>\n","      <td>SF</td>\n","      <td>146</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0.00</td>\n","      <td>0.60</td>\n","      <td>0.88</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>normal</td>\n","      <td>15</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>tcp</td>\n","      <td>private</td>\n","      <td>S0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0.10</td>\n","      <td>0.05</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>1.00</td>\n","      <td>1.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>neptune</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>tcp</td>\n","      <td>http</td>\n","      <td>SF</td>\n","      <td>232</td>\n","      <td>8153</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>1.00</td>\n","      <td>0.00</td>\n","      <td>0.03</td>\n","      <td>0.04</td>\n","      <td>0.03</td>\n","      <td>0.01</td>\n","      <td>0.00</td>\n","      <td>0.01</td>\n","      <td>normal</td>\n","      <td>21</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>tcp</td>\n","      <td>http</td>\n","      <td>SF</td>\n","      <td>199</td>\n","      <td>420</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>1.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>normal</td>\n","      <td>21</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>125968</th>\n","      <td>0</td>\n","      <td>tcp</td>\n","      <td>private</td>\n","      <td>S0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0.10</td>\n","      <td>0.06</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>1.00</td>\n","      <td>1.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>neptune</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>125969</th>\n","      <td>8</td>\n","      <td>udp</td>\n","      <td>private</td>\n","      <td>SF</td>\n","      <td>105</td>\n","      <td>145</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0.96</td>\n","      <td>0.01</td>\n","      <td>0.01</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>normal</td>\n","      <td>21</td>\n","    </tr>\n","    <tr>\n","      <th>125970</th>\n","      <td>0</td>\n","      <td>tcp</td>\n","      <td>smtp</td>\n","      <td>SF</td>\n","      <td>2231</td>\n","      <td>384</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0.12</td>\n","      <td>0.06</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.72</td>\n","      <td>0.00</td>\n","      <td>0.01</td>\n","      <td>0.00</td>\n","      <td>normal</td>\n","      <td>18</td>\n","    </tr>\n","    <tr>\n","      <th>125971</th>\n","      <td>0</td>\n","      <td>tcp</td>\n","      <td>klogin</td>\n","      <td>S0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0.03</td>\n","      <td>0.05</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>1.00</td>\n","      <td>1.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>neptune</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>125972</th>\n","      <td>0</td>\n","      <td>tcp</td>\n","      <td>ftp_data</td>\n","      <td>SF</td>\n","      <td>151</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0.30</td>\n","      <td>0.03</td>\n","      <td>0.30</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>normal</td>\n","      <td>21</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>125973 rows × 43 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f0cf3a28-edf6-4e49-91ac-11878c44c693')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f0cf3a28-edf6-4e49-91ac-11878c44c693 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f0cf3a28-edf6-4e49-91ac-11878c44c693');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":6}],"source":["# Column names for the dataset\n","cols = ['duration','protocol_type','service','flag','src_bytes','dst_bytes','land','wrong_fragment','urgent','hot',\n","        'num_failed_logins','logged_in','num_compromised','root_shell','su_attempted','num_root','num_file_creations',\n","        'num_shells','num_access_files','num_outbound_cmds','is_host_login','is_guest_login','count','srv_count',\n","        'serror_rate','srv_serror_rate','rerror_rate','srv_rerror_rate','same_srv_rate','diff_srv_rate',\n","        'srv_diff_host_rate','dst_host_count','dst_host_srv_count','dst_host_same_srv_rate','dst_host_diff_srv_rate',\n","        'dst_host_same_src_port_rate','dst_host_srv_diff_host_rate','dst_host_serror_rate','dst_host_srv_serror_rate',\n","        'dst_host_rerror_rate','dst_host_srv_rerror_rate','target','difficulty']\n","\n","# Read in the training dataset\n","train_df = pd.read_csv(\"/content/KDDTrain.csv\", names = cols)\n","\n","# Read in the training dataset\n","test_df = pd.read_csv(\"/content/KDDTest.csv\", names = cols)\n","\n","# Output the top 5 records of the training set\n","print(\"Training Set:\")\n","train_df"]},{"cell_type":"code","execution_count":null,"id":"4a51c403","metadata":{"id":"4a51c403"},"outputs":[],"source":["# Output the top 5 records of the test set\n","print(\"Test Set:\")\n","test_df.head()"]},{"cell_type":"code","execution_count":null,"id":"8c7de2d3","metadata":{"scrolled":true,"id":"8c7de2d3"},"outputs":[],"source":["# Drop the difficulty feature from both datasets\n","train_df.drop(columns=['difficulty'], inplace=True)\n","test_df.drop(columns=['difficulty'], inplace=True)\n","\n","# Output dataframe information for the training set\n","train_df.info()"]},{"cell_type":"code","execution_count":null,"id":"4489dfa5","metadata":{"scrolled":true,"id":"4489dfa5"},"outputs":[],"source":["# Output dataframe information for the test set\n","test_df.info()"]},{"cell_type":"markdown","id":"e183b68f","metadata":{"id":"e183b68f"},"source":["#  <span style=\"color:#0b186c;\">Data Preprocessing</span><a class=\"anchor\" id=\"third-bullet\"></a>\n","\n","---\n","\n","Data Preprocessing is the process of selecting and/or transforming existing features (columns) in the raw data to make the data compatible with the chosen machine learning model and improve the model’s predictive performance against the data. The appropriate preprocessing techniques for a particular model requires knowledge of how the model interprets the different features, as well as domain expertise pertaining to the data itself. Otherwise, if done improperly, the resulting predictions could be inaccurate, or the dependencies could be misinterpreted by the model. \n","\n","Common Data Preprocessing techniques include:\n","\n","- Imputation\n","- Log Transformations\n","- Encoding\n","- Feature Selection\n","- Scaling\n"]},{"cell_type":"markdown","id":"92579948","metadata":{"id":"92579948"},"source":["## <span style=\"color:#0b186c;\">Numerical Features</span>"]},{"cell_type":"code","execution_count":null,"id":"aff4fed2","metadata":{"id":"aff4fed2"},"outputs":[],"source":["# Select the columns in the training set with numerical dtypes\n","num_cols = train_df.select_dtypes(include=['int64', 'float64']).columns\n","\n","# Create a 4x5 figure to plot the first 20 box plots\n","fig, axes = plt.subplots(4, 5)\n","fig.suptitle('Training Set', fontsize=20)\n","for ax, col in zip(axes.ravel(), num_cols[0:20]):\n","    train_df[col].value_counts().plot(ax=ax, kind='box', figsize=(20, 20), fontsize=10)\n","    ax.set_title(str(col), fontsize = 12)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"8de9cdeb","metadata":{"id":"8de9cdeb"},"outputs":[],"source":["# Create a 3x6 figure to plot the remaining 18 box plots\n","fig, axes = plt.subplots(3, 6)\n","fig.suptitle('Training Set', fontsize=20)\n","for ax, col in zip(axes.ravel(), num_cols[20:]):\n","    train_df[col].value_counts().plot(ax=ax, kind='box', figsize=(20, 20), fontsize=10)\n","    ax.set_title(str(col), fontsize = 12)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"8a6b5076","metadata":{"id":"8a6b5076"},"outputs":[],"source":["# Select the columns in the test set with numerical dtypes\n","num_cols = test_df.select_dtypes(include=['int64', 'float64']).columns\n","\n","# Create a 4x5 figure to plot the first 20 box plots\n","fig, axes = plt.subplots(4, 5)\n","fig.suptitle('Test Set', fontsize=20)\n","for ax, col in zip(axes.ravel(), num_cols[0:20]):\n","    test_df[col].value_counts().plot(ax=ax, kind='box', figsize=(20, 20), fontsize=10)\n","    ax.set_title(str(col), fontsize = 12)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"9d443809","metadata":{"id":"9d443809"},"outputs":[],"source":["# Create a 3x6 figure to plot the remaining 18 box plots\n","fig, axes = plt.subplots(3, 6)\n","fig.suptitle('Test Set', fontsize=20)\n","for ax, col in zip(axes.ravel(), num_cols[20:]):\n","    test_df[col].value_counts().plot(ax=ax, kind='box', figsize=(20, 20), fontsize=10)\n","    ax.set_title(str(col), fontsize = 12)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"19040ed7","metadata":{"id":"19040ed7"},"outputs":[],"source":["# Instantiate the scaler\n","scaler = RobustScaler()\n","\n","# Fit and transform the numerical columns in the training set\n","train_df[num_cols] = scaler.fit_transform(train_df[num_cols])\n","\n","# Review the changes made to the training set\n","train_df"]},{"cell_type":"code","execution_count":null,"id":"5d08c687","metadata":{"id":"5d08c687"},"outputs":[],"source":["# Transform the numerical test columns in the test set\n","test_df[num_cols] = scaler.transform(test_df[num_cols])\n","\n","# Review the changes made to the test set\n","test_df"]},{"cell_type":"markdown","id":"a5f5627a","metadata":{"id":"a5f5627a"},"source":["## <span style=\"color:#0b186c;\">Categorical Features</span>"]},{"cell_type":"code","execution_count":null,"id":"54dbf1dc","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"id":"54dbf1dc","executionInfo":{"status":"error","timestamp":1664397848922,"user_tz":240,"elapsed":192,"user":{"displayName":"Chandler Provence","userId":"03181162782867069084"}},"outputId":"123bfcfe-a440-44e2-82b0-081b8da8d2d5"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-e70601217ec0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Select the columns in the training set with dtype of object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mobj_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Create a 2x2 figure to plot pie charts of the categorical distributions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"]}],"source":["# Select the columns in the training set with dtype of object\n","obj_cols = train_df.select_dtypes(include='object').columns\n","\n","# Create a 2x2 figure to plot pie charts of the categorical distributions\n","fig, axes = plt.subplots(2, 2)\n","fig.suptitle('Training Set', fontsize=20)\n","for ax, col in zip(axes.ravel(), obj_cols):\n","    train_df[col].value_counts().plot(ax=ax, kind='pie', figsize=(15, 15), fontsize=10, autopct='%1.0f%%')\n","    ax.set_title(str(col), fontsize = 12)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"b715e95d","metadata":{"id":"b715e95d"},"outputs":[],"source":["# Select the columns in the test set with dtype of object\n","obj_cols = test_df.select_dtypes(include='object').columns\n","\n","# Create a 2x2 figure to plot pie charts of the categorical distributions\n","fig, axes = plt.subplots(2, 2)\n","fig.suptitle('Test Set', fontsize=20)\n","for ax, col in zip(axes.ravel(), obj_cols):\n","    test_df[col].value_counts().plot(ax=ax, kind='pie', figsize=(15, 15), fontsize=10, autopct='%1.0f%%')\n","    ax.set_title(str(col), fontsize = 12)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"bb502af2","metadata":{"id":"bb502af2"},"outputs":[],"source":["# Instantiate the ordinal encoder\n","oe = OrdinalEncoder(dtype=int, handle_unknown = 'use_encoded_value', unknown_value = 999)\n","\n","# Fit the encoder on the flag feature  \n","oe.fit(train_df[['flag']])\n","\n","# View the identified categories in the fitted feature\n","oe.categories_"]},{"cell_type":"code","execution_count":null,"id":"011b3e6b","metadata":{"id":"011b3e6b"},"outputs":[],"source":["# Transform the identified categories into numerical representations\n","train_df['flag'] = oe.transform(train_df[['flag']])\n","\n","# Review the changes made to the flag feature in the training set\n","train_df"]},{"cell_type":"code","execution_count":null,"id":"24d31128","metadata":{"id":"24d31128"},"outputs":[],"source":["# Transform the identified categories into numerical representations\n","test_df['flag'] = oe.transform(test_df[['flag']])\n","\n","# Review the changes made to the flag feature in the test set\n","test_df"]},{"cell_type":"code","execution_count":null,"id":"b95b7d1a","metadata":{"id":"b95b7d1a"},"outputs":[],"source":["# Fit on the service feature and transform in place\n","train_df['service'] = oe.fit_transform(train_df[['service']])\n","\n","# Verify changes made to the training set\n","train_df"]},{"cell_type":"code","execution_count":null,"id":"fae66c86","metadata":{"id":"fae66c86"},"outputs":[],"source":["# Transform the categories identified in training for the test set\n","test_df['service'] = oe.transform(test_df[['service']])\n","\n","# Verify changes made to the test set\n","test_df"]},{"cell_type":"code","execution_count":null,"id":"4253e324","metadata":{"id":"4253e324"},"outputs":[],"source":["# Instantiate the one hot encoder\n","ohe = OneHotEncoder(sparse=False, dtype=int)\n","\n","# Fit the encoder on the appropriate column\n","ohe.fit(train_df[['protocol_type']])\n","\n","# Select the categories identified by the encoder\n","col = ohe.categories_\n","\n","# Run transform to one hot encode the column, adding the new columns to the dataframe\n","train_df[col[0]] = ohe.transform(train_df[['protocol_type']])\n","\n","# Drop the original column, not needed anymore\n","train_df.drop(columns=['protocol_type'], inplace=True)\n","\n","# Review the changes made to the training set\n","train_df"]},{"cell_type":"code","execution_count":null,"id":"3998acf8","metadata":{"id":"3998acf8"},"outputs":[],"source":["# Run transform to one hot encode the column, adding the new columns to the dataframe\n","test_df[col[0]] = ohe.transform(test_df[['protocol_type']])\n","\n","# Drop the original column, not needed anymore\n","test_df.drop(columns=['protocol_type'], inplace=True)\n","\n","# Review the changes made to the test set\n","test_df"]},{"cell_type":"code","execution_count":null,"id":"95ff7b94","metadata":{"id":"95ff7b94"},"outputs":[],"source":["# Assign 0 for normal and 1 for intrusion in the target variable in both sets\n","train_df.loc[(train_df.target == 'normal'), 'target'] = 0\n","train_df.loc[(train_df.target != 0), 'target'] = 1\n","\n","test_df.loc[(test_df.target == 'normal'), 'target'] = 0\n","test_df.loc[(test_df.target != 0), 'target'] = 1\n","\n","# Visualize the altered target variable distributions\n","fig, axes = plt.subplots(1, 2)\n","c1 = ['#1f77b4', '#d62728']\n","c2 = ['#d62728', '#1f77b4']\n","train_df.target.value_counts().plot(ax=axes[0], kind='pie', colors = c1, \n","                                    figsize=(15, 15), fontsize=10, autopct='%1.0f%%')\n","test_df.target.value_counts().plot(ax=axes[1], kind='pie', colors = c2,\n","                                   figsize=(15, 15), fontsize=10, autopct='%1.0f%%')"]},{"cell_type":"markdown","id":"e0c347f6","metadata":{"id":"e0c347f6"},"source":["#  <span style=\"color:#0b186c;\">Initial Model Development</span><a class=\"anchor\" id=\"fourth-bullet\"></a>\n","\n","---\n","\n","Since the dataset contains a labeled target variable, which we have scoped for binary classification of intrusions and normal network activity, we can leverage classification models for predictions on future data. As discussed previously, Decision Trees are one of the most popular types of classification algorithms due to their flexibility and overall performance. \n","\n","First, we will split the data into independent variables (X) and the dependent variable (y) for both the training and test sets. Since the data has already been partioned for us, we will not need to use the `train_test_split()"]},{"cell_type":"code","execution_count":null,"id":"6839a894","metadata":{"id":"6839a894"},"outputs":[],"source":["# Separate X and y for the training set\n","y_train = train_df.pop('target').astype('int')\n","X_train = train_df\n","\n","X_train"]},{"cell_type":"code","execution_count":null,"id":"98caf146","metadata":{"id":"98caf146"},"outputs":[],"source":["# Separate X and y for the test set\n","y_test = test_df.pop('target').astype('int')\n","X_test = test_df\n","\n","X_test"]},{"cell_type":"markdown","id":"d185942a","metadata":{"id":"d185942a"},"source":["The Decision Tree model can be loaded directly from `scikit-learn`.\n","\n","\n","https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"]},{"cell_type":"code","execution_count":null,"id":"d7547a42","metadata":{"id":"d7547a42"},"outputs":[],"source":["# Instantiate the classifier\n","classifier = DecisionTreeClassifier()\n","\n","# Fit the model on the training data\n","classifier.fit(X_train, y_train)\n","\n","fig = plt.figure(figsize=(25,20))\n","_ = tree.plot_tree(classifier, \n","                   max_depth = 2,\n","                   feature_names= X_train.columns,  \n","                   class_names = ['Normal', 'Intrusion'],\n","                   filled = True)"]},{"cell_type":"code","execution_count":null,"id":"fe3df821","metadata":{"id":"fe3df821"},"outputs":[],"source":["# Make predictions based on the X values in the test set\n","y_pred = classifier.predict(X_test)\n","\n","# Calculate the accuracy score of the test set\n","score = round((accuracy_score(y_test, y_pred) * 100), 2)\n","\n","# changing the rc parameters to adjust the size\n","plt.rcParams['figure.figsize'] = [10, 10]\n","\n","#Plot the confusion Matrix for the predictions\n","fig = plot_confusion_matrix(classifier, X_test, y_test, cmap = plt.cm.Blues)\n","fig.ax_.set_title(\"Confusion Matrix\")\n","plt.show()\n","\n","\n","print(f\"Accuracy = {score}%\")"]},{"cell_type":"markdown","id":"ab8b4e08","metadata":{"id":"ab8b4e08"},"source":["#  <span style=\"color:#0b186c;\">Dimensionality Reduction</span><a class=\"anchor\" id=\"fifth-bullet\"></a>\n","\n","---\n","\n","The number of input variables or features for a dataset is referred to as its dimensionality. More input features often make a predictive modeling task more challenging, generally due to the interpretability of feature importance and variance. Therefore, dimensionality reduction techniques are popular for handling data with hundreds, or even thousands, of features. One such technique, Principal Component Analysis (PCA), is a dimensionality reduction method that transforms the data to a new basis where the dimensions are non-redundant (low covariance) and have high variance. PCA is an Unsupervised Learning method and can be loaded directly from `scikit-learn`.\n","\n","https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html"]},{"cell_type":"code","execution_count":null,"id":"10952a93","metadata":{"id":"10952a93"},"outputs":[],"source":["# Review the training dataframe, it should not have the target label present\n","train_df"]},{"cell_type":"code","execution_count":null,"id":"a8b16a83","metadata":{"id":"a8b16a83"},"outputs":[],"source":["# Instantiate the PCA\n","pca = PCA()\n","\n","# Fit pca on the training data\n","pca.fit(train_df)\n","\n","# Plot the principal components against their inertia\n","features = range(pca.n_components_)\n","_ = plt.figure(figsize=(15, 5))\n","_ = plt.bar(features, pca.explained_variance_)\n","_ = plt.xlabel('Principal Component')\n","_ = plt.ylabel('Variance')\n","_ = plt.xticks(features)\n","_ = plt.title(\"Importance of the Principal Components Based on Inertia\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"474534fe","metadata":{"id":"474534fe"},"outputs":[],"source":["# Instantiate pca with the optimal number of components\n","pca = PCA(n_components=3)\n","\n","# Since we reduced the number of features, we are going to use new column names\n","pc_columns = ['pc_%i' % i for i in range(3)]\n","\n","# Transform the training data into reduced dimensions of 3 principal components\n","pca_train = pd.DataFrame(pca.fit_transform(train_df), columns = pc_columns, index = train_df.index)\n","\n","# View the transformed dataframe\n","pca_train"]},{"cell_type":"code","execution_count":null,"id":"cb9a939c","metadata":{"id":"cb9a939c"},"outputs":[],"source":["# Transform the test data into reduced dimensions of 3 principal components\n","pca_test = pd.DataFrame(pca.transform(test_df), columns = pc_columns, index = test_df.index)\n","\n","# View the transformed dataframe\n","pca_test"]},{"cell_type":"code","execution_count":null,"id":"72c2975a","metadata":{"id":"72c2975a"},"outputs":[],"source":["# Fit the model on the training data\n","classifier.fit(pca_train, y_train)\n","\n","fig = plt.figure(figsize=(25,20))\n","_ = tree.plot_tree(classifier, \n","                   max_depth = 2,\n","                   feature_names= pca_train.columns,  \n","                   class_names = ['Normal', 'Intrusion'],\n","                   filled = True)"]},{"cell_type":"code","execution_count":null,"id":"8ad3792c","metadata":{"id":"8ad3792c"},"outputs":[],"source":["# Make predictions based on the X values in the test set\n","y_pred = classifier.predict(pca_test)\n","\n","# Calculate the accuracy score of the test set\n","score = round((accuracy_score(y_test, y_pred) * 100), 2)\n","\n","# changing the rc parameters to adjust the size\n","plt.rcParams['figure.figsize'] = [10, 10]\n","\n","#Plot the confusion Matrix for the predictions\n","fig = plot_confusion_matrix(classifier, pca_test, y_test, cmap = plt.cm.Blues)\n","fig.ax_.set_title(\"Confusion Matrix\")\n","plt.show()\n","\n","\n","print(f\"Accuracy = {score}%\")"]},{"cell_type":"markdown","id":"2819ab1b","metadata":{"id":"2819ab1b"},"source":["#  <span style=\"color:#0b186c;\">Conclusion</span><a class=\"anchor\" id=\"sixth-bullet\"></a>\n","\n","---\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"colab":{"provenance":[],"collapsed_sections":["a5f5627a"]}},"nbformat":4,"nbformat_minor":5}