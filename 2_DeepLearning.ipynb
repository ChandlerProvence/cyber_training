{"cells":[{"cell_type":"markdown","id":"a5a87fce","metadata":{"id":"a5a87fce"},"source":["#  <span style=\"color:#0b186c;\">Introduction to Deep Learning</span>\n","\n","---\n","\n","“Deep learning is a subset of machine learning that's based on artificial neural networks. The learning process is deep because the structure of artificial neural networks consists of multiple input, output, and hidden layers. Each layer contains units that transform the input data into information that the next layer can use for a certain predictive task. Thanks to this structure, a machine can learn through its own data processing.” - Microsoft, 2022\n","\n","\n","## <span style=\"color:#0b186c;\">Table of Contents:</span>\n","* [Artificial Neural Networks (ANNs)](#first-bullet)\n","* [Hello World](#second-bullet)\n","* [Dataset Information](#third-bullet)\n","* [Multilayer Perceptron (MLP)](#fourth-bullet)\n","* [Sequential Model](#fifth-bullet)\n","* [Conclusion](#sixth-bullet)"]},{"cell_type":"markdown","id":"a472d334","metadata":{"id":"a472d334"},"source":["#  <span style=\"color:#0b186c;\">Artificial Neural Networks (ANNs)</span><a class=\"anchor\" id=\"first-bullet\"></a>\n","\n","---\n","\n","Artificial Neural Networks (ANNs) are composed of artificial neurons, or nodes, that mimic the learning paths of the human brain. The ANN can contain any number of neurons organized in the form of any number of interconnected layers. The first layer, the input layer, contains nodes representing the features in the dataset used to train the model. The final layer, or output layer, indicates the dimentionality of the target variable. The layers between the input and output are hidden layers containing connections modeled as weights, which represent the neuron's interpretation of feature importance in predicting the output value. ANNs also use Bias, a constant parameter which helps adjust the weighted sum of the inputs to the neuron for the best fit on the data. Lastly, Activation Functions are non-linear transformations that define the output of a neuron before sending it to the next layer of neurons or finalizing the output determination of the model.\n","\n","\n","There are many different libraries associated with Deep Learning in Python, however, PyTorch and Tensorflow are two of the most common open-source frameworks used to create Neural Networks. While Tensorflow is an end-to-end open-source library for ML and DL, interfacing is accomplished through a library called Keras. There are 2 primary ways to create a Keras model:\n","\n","- The Functional API, which is the easy-to-use, fully-featured API supporting arbitrary model architectures.\n","- The Sequential model, which is a limited single-input, single-output stack of layers (ordered sequentially).\n","\n","\n","## <span style=\"color:#0b186c;\">Required Imports:</span>\n","\n","<div class=\"alert alert-warning\">\n","\n","<b>Note:</b> If you have not previously installed these `packages`, you can use the cell below to perform the required `pip` installs.\n","\n","</div>"]},{"cell_type":"code","execution_count":null,"id":"0b5d95a3","metadata":{"id":"0b5d95a3"},"outputs":[],"source":["# In case you still need to perform some pip installs:\n","! pip install --user pandas -q\n","! pip install --user numpy -q\n","! pip install --user tensorflow -q"]},{"cell_type":"code","execution_count":null,"id":"5e6ec529","metadata":{"id":"5e6ec529"},"outputs":[],"source":["# Dataframe and array libraries\n","import pandas as pd\n","import numpy as np\n","\n","# Libraries for visualizing data\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Retrieves the dataset from Scikit-learn\n","from sklearn.datasets import load_iris\n","\n","# Required for performing standardization\n","from sklearn.preprocessing import StandardScaler\n","\n","# Required for training and validating a model\n","from sklearn.model_selection import train_test_split\n","\n","# Required for instantiating and running the MLP neural network\n","from sklearn.neural_network import MLPClassifier\n","\n","# Classification metrics and confusion matrix\n","from sklearn.metrics import confusion_matrix, accuracy_score, plot_confusion_matrix, ConfusionMatrixDisplay\n","\n","# Required for instantiating and building Sequential neural networks\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","# Filters out warning messages\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","id":"b4784df1","metadata":{"id":"b4784df1"},"source":["#  <span style=\"color:#0b186c;\">Hello World</span><a class=\"anchor\" id=\"second-bullet\"></a>\n","\n","---\n","\n","Neural networks learn how to appropriately weight the feature importance of input variables to be mapped to an output through an iterative learning process. The mathematical relationship between the various input variables and the output variable is approximated by the neural network model and is used to make predictions on future values. The simplest form of a Neural Network is a single neuron with only one interconnected layer. In Keras, the word for a simple, interconnected layer is `Dense`. \n","\n","In the cells below, we instantiate an array of `x` values that have a straightforward, mathematical relationship to their corresponding `y` values. Next, we build a single-layered `model` with one `unit` (neuron). We then `compile` the model by defining a `loss` and `optimizer` function. Since the model doesn't know the relationship between the x and y values, it has to guess. The loss function defines how the effectiveness of the model's guess is evaluated and scored by comparing the guessed answers with the known correct answers in the dataset. After each guess, the optimizer defines the logic used to update the weights learned by the model to minimize the loss function. This process continues iteratively for the defined number of `epochs` in the `fit` function."]},{"cell_type":"code","execution_count":null,"id":"b23f8fbc","metadata":{"id":"b23f8fbc"},"outputs":[],"source":["# First, let's create some data with an easily discernable pattern\n","xs = np.array([0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0], dtype=float)\n","ys = np.array([-1.0, 9.0, 19.0, 29.0, 39.0, 49.0, 59.0, 69.0, 79.0, 89.0], dtype=float)\n","\n","# Build a simple Sequential model\n","model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])\n","\n","# Compile the model\n","model.compile(optimizer='sgd', loss='mean_squared_error')\n","\n","# Train the model\n","model.fit(xs, ys, epochs=100)"]},{"cell_type":"code","execution_count":null,"id":"5f123d42","metadata":{"id":"5f123d42"},"outputs":[],"source":["# Make a prediction\n","print(model.predict([10.0]))"]},{"cell_type":"markdown","id":"d8f95c20","metadata":{"id":"d8f95c20"},"source":["<div class=\"alert alert-warning\">\n","\n","It is important to remember that the output of Neural Networks deals in probability. Based on the input data provided to the model, it approximates the probability of the relationship mapping between x and y. While we may be able to identify the relationship between these 10 data points mathematically, the model does not deal in certainties. Therefore, the output of our prediction may be very close, but not necessarily the exact answer.\n","\n","</div>"]},{"cell_type":"markdown","id":"dd0d7a96","metadata":{"id":"dd0d7a96"},"source":["#  <span style=\"color:#0b186c;\">Dataset Information</span><a class=\"anchor\" id=\"third-bullet\"></a>\n","\n","---\n","\n","We will be using a dataset containing 3 species in the Iris genus, namely, Iris Setosa, Iris Versicolor and Iris Virginica found in the Gaspé Peninsula. For the purposes of an integral study, the collected Iris samples were, \"all from the same pasture, and picked on the same day and measured at the same time by the same person with the same apparatus.\" The dataset contains 150 rows of data, 50 rows of data for each species of Iris flower. The column names represent the feature of the flower that was studied and recorded.\n","\n","Our target dataset can be found in the Scikit-learn library, so we will be importing it directly from the library and storing it into a Pandas dataframe.\n","\n","https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html\n","\n","<div class=\"alert alert-success\">\n","    \n","Using the cell below, load the Iris dataset from scikit-learn into a pandas dataframe and output the first 5 observations:\n","\n","</div>"]},{"cell_type":"code","execution_count":null,"id":"196c839f","metadata":{"id":"196c839f"},"outputs":[],"source":["# Import the iris dataset\n","\n","# Place the dataset into a dataframe\n","\n","# View the first 5 records in the dataset\n"]},{"cell_type":"markdown","id":"be688647","metadata":{"id":"be688647"},"source":["<div class=\"alert alert-success\">\n","    \n","Using the cell below, view important information about the dataframe:\n","\n","</div>"]},{"cell_type":"code","execution_count":null,"id":"94061d16","metadata":{"id":"94061d16"},"outputs":[],"source":["# Dataframe info\n"]},{"cell_type":"markdown","id":"0c7de5db","metadata":{"id":"0c7de5db"},"source":["<div class=\"alert alert-success\">\n","    \n","Using the cell below, view statistical information about the numerical variables in the dataframe:\n","\n","</div>"]},{"cell_type":"code","execution_count":null,"id":"2b8ecc29","metadata":{"id":"2b8ecc29"},"outputs":[],"source":["# Numeric variable statistics\n"]},{"cell_type":"markdown","id":"5d8f5dba","metadata":{"id":"5d8f5dba"},"source":["<div class=\"alert alert-success\">\n","    \n","Using the cell below, plot a `.pairplot()` using the `seaborn` library:\n","\n","</div>"]},{"cell_type":"code","execution_count":null,"id":"5db1ce2a","metadata":{"id":"5db1ce2a"},"outputs":[],"source":["# Create a pairplot\n"]},{"cell_type":"markdown","id":"a6df91f0","metadata":{"id":"a6df91f0"},"source":["<div class=\"alert alert-success\">\n","    \n","Using the cell below, plot a pie chart of the target variable distributions:\n","\n","</div>"]},{"cell_type":"code","execution_count":null,"id":"31f866de","metadata":{"id":"31f866de"},"outputs":[],"source":["# Create a pie chart for the target variable\n"]},{"cell_type":"markdown","id":"77c858b1","metadata":{"id":"77c858b1"},"source":["#  <span style=\"color:#0b186c;\">Multilayer Perceptron (MLP)</span><a class=\"anchor\" id=\"fourth-bullet\"></a>\n","\n","---\n","\n","A Mulilayer Perceptron (MLP) network is a fully connected, feedforward ANN consisting of an input layer, one or more hidden layers, and an output layer. This type of network is sometimes used to ambiguously refer to *any* type of ANN, however, it can also refer to specific ones (e.g., specific activation functions, specific perceptron algorithm variations, etc.). \n","\n","The `scikit-learn` library includes 2 variations of an MLP model in the form of a regressor and a classifier. The primary difference between them is the loss and activation functions. Since the iris dataset includes a discrete, categorical target variable, we will be using the `MLPClassifier()`.\n","\n","https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n","\n","<div class=\"alert alert-success\">\n","    \n","First, split the data into independent variables (X) and the dependent target variable (y):\n","\n","</div>"]},{"cell_type":"code","execution_count":null,"id":"73184912","metadata":{"id":"73184912"},"outputs":[],"source":["# Split the independent (X) and dependent (y) variables\n"]},{"cell_type":"markdown","id":"fba6d5b6","metadata":{"id":"fba6d5b6"},"source":["<div class=\"alert alert-success\">\n","    \n","Partition the data into an **80/20** split for training and testing using the `train_test_split()` function:\n","\n","</div>"]},{"cell_type":"code","execution_count":null,"id":"ab200f7a","metadata":{"id":"ab200f7a"},"outputs":[],"source":["# Split the data into an 80/20\n","\n","# Output the shape of the training shape\n"]},{"cell_type":"markdown","id":"f1eed654","metadata":{"id":"f1eed654"},"source":["<div class=\"alert alert-success\">\n","    \n","Use the `StandardScaler()` to `.fit_transform()` the training set and `.transform()` the test set:\n","\n","</div>"]},{"cell_type":"code","execution_count":null,"id":"8500ef9d","metadata":{"id":"8500ef9d"},"outputs":[],"source":["# Instantiate the standard scaler\n","\n","# Fit and transform the scaler on the training set\n","\n","# Transform the fit scaler on the test set\n"]},{"cell_type":"markdown","id":"0171365c","metadata":{"id":"0171365c"},"source":["<div class=\"alert alert-info\">\n","    \n","&nbsp;**Note:** The output layer activation function is determined automatically by the `MLPClassifier` internally. Binary classification problems will use the `Logistic` activation function and multi-class classification problems will use the `Softmax` activation function.\n","\n","</div>"]},{"cell_type":"code","execution_count":null,"id":"904654ff","metadata":{"id":"904654ff"},"outputs":[],"source":["# Instantiate the MLP ANN\n","MLP = MLPClassifier()\n","\n","# Fit the ANN on the training data\n","MLP.fit(X_train, y_train)\n","\n","# Verify the output activation function is softmax\n","MLP.out_activation_"]},{"cell_type":"code","execution_count":null,"id":"28fe4e89","metadata":{"id":"28fe4e89"},"outputs":[],"source":["# Make predictions based on the X values in the test set\n","y_pred = MLP.predict(X_test)\n","\n","# Calculate the accuracy score of the test set\n","score = round((accuracy_score(y_test, y_pred) * 100), 2)\n","\n","# changing the rc parameters to adjust the size\n","plt.rcParams['figure.figsize'] = [10, 10]\n","\n","#Plot the confusion Matrix for the predictions\n","fig = plot_confusion_matrix(MLP, X_test, y_test, cmap = plt.cm.Blues)\n","fig.ax_.set_title(\"Confusion Matrix\")\n","plt.show()\n","\n","# Print the accuracy score on the validation data\n","print(f\"Accuracy = {score}%\")"]},{"cell_type":"markdown","id":"331e4f64","metadata":{"id":"331e4f64"},"source":["#  <span style=\"color:#0b186c;\">Sequential Model</span><a class=\"anchor\" id=\"fifth-bullet\"></a>\n","\n","---\n","\n","Expanding on our initial discussion on the `Sequential` model from Tensorflow, we can modify the layer architecture to create much more adaptable and robust solutions for more complex problems. While the Iris dataset is not necessarily complex, it is slightly more involved than a single input X value and a strong, linearly related y value. Therefore, we will add a couple more layers to our layer architecture and introduce activation functions.\n","\n","<div class=\"alert alert-info\">\n","\n","The `ReLU` (Rectified Linear Unit) activation function is one of the most widely used activation functions in neural networks. It is a non-linear function that outputs the input value to the neuron directly if it is positive, otherwise, it converts the output to 0 and the neuron does not get activated.\n","    \n","The `softmax` activation function is used for neural networks that predict multinomial probability distribution. This means the dependent variable contains more than 2 class labels (multi-class classification).\n","\n","</div>"]},{"cell_type":"code","execution_count":null,"id":"5fb49a4d","metadata":{"id":"5fb49a4d"},"outputs":[],"source":["# Build Sequential model using Dense layers\n","model = tf.keras.models.Sequential([keras.layers.Dense(4, input_shape=[4]),\n","                                    keras.layers.Dense(16, activation=tf.nn.relu),\n","                                    keras.layers.Dense(3, activation=tf.nn.softmax)])\n","model.summary()"]},{"cell_type":"markdown","id":"c08e1ef7","metadata":{"id":"c08e1ef7"},"source":["<div class=\"alert alert-warning\">\n","\n","Since we are using an activation function in our output layer, we must also change the `optimizer` and `loss` functions to appropriately reflect the change in our model's iterative learning process. \n","\n","</div>"]},{"cell_type":"code","execution_count":null,"id":"5e75aa00","metadata":{"id":"5e75aa00"},"outputs":[],"source":["# Compile the model with appropriate optimizer and loss functions\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# Train the neural network on 100 epochs\n","model.fit(X_train, y_train, epochs=100)"]},{"cell_type":"code","execution_count":null,"id":"b4baead1","metadata":{"id":"b4baead1"},"outputs":[],"source":["# Plot the model performance over epochs\n","losses = pd.DataFrame(model.history.history)\n","losses.plot()"]},{"cell_type":"code","execution_count":null,"id":"4583dfb8","metadata":{"id":"4583dfb8"},"outputs":[],"source":["# Make predictions of y_test based on X_test, view probabilities output\n","y_pred = model.predict(X_test)\n","y_pred"]},{"cell_type":"code","execution_count":null,"id":"647ea735","metadata":{"id":"647ea735"},"outputs":[],"source":["# Convert probabilities to labels, compare with true values\n","y_pred = np.argmax(y_pred, axis=-1)    \n","\n","# Calculate the accuracy score of the test set\n","score = round((accuracy_score(y_test, y_pred) * 100), 2)\n","\n","# Print the accuracy score on the validation data\n","print(f\"Accuracy = {score}%\")"]},{"cell_type":"markdown","id":"3b1ef63c","metadata":{"id":"3b1ef63c"},"source":["<div class=\"alert alert-info\">\n","\n","Alternatively, the validation can happen simultaneously at each epoch by passing the test data in the `validation_data` parameter of the `.fit()` method.\n","\n","</div>"]},{"cell_type":"code","execution_count":null,"id":"aea0897a","metadata":{"id":"aea0897a"},"outputs":[],"source":["# Build Sequential model using Dense layers\n","model = tf.keras.models.Sequential([keras.layers.Dense(4, input_shape=[4]),\n","                                    keras.layers.Dense(16, activation=tf.nn.relu),\n","                                    keras.layers.Dense(3, activation=tf.nn.softmax)])\n","\n","# Compile the model with appropriate optimizer and loss functions\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# Train the neural network on 100 epochs\n","model.fit(X_train, y_train, epochs=100, validation_data = (X_test, y_test))"]},{"cell_type":"code","execution_count":null,"id":"8575ed77","metadata":{"id":"8575ed77"},"outputs":[],"source":["# Plot the model performance over epochs\n","losses = pd.DataFrame(model.history.history)\n","losses.plot()"]},{"cell_type":"markdown","id":"01eecca6","metadata":{"id":"01eecca6"},"source":["#  <span style=\"color:#0b186c;\">Conclusion</span><a class=\"anchor\" id=\"sixth-bullet\"></a>\n","\n","---\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"colab":{"provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":5}